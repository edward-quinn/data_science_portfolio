[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Edward B. Quinn, PhD, MPH",
    "section": "",
    "text": "I am a Senior Data Analyst and a published health researcher. My PhD training was in epigenetics and health equity, where I used R to analyze over 400 million data points.\nMy skill set is currently expanding to include Shiny, SQL, Python, and Tableau. In my spare time, I love to travel and watch mixed martial arts."
  },
  {
    "objectID": "python_projects.html",
    "href": "python_projects.html",
    "title": "Python",
    "section": "",
    "text": "First Python Project\n\n\n\n\n\n\nPython\n\n\n\n\n\n\n\n\n\nJul 30, 2023\n\n\nEdward B. Quinn, PhD, MPH\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "r_projects/post-with-code/index.html",
    "href": "r_projects/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\nCode1 + 1\n\n[1] 2\n\n\nAnd now what if I add more?\n\nCode2+5\n\n[1] 7\n\n\nDoes Markdown work too?\n\nCheck it out."
  },
  {
    "objectID": "r_projects/welcome/index.html",
    "href": "r_projects/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "r_projects.html",
    "href": "r_projects.html",
    "title": "R",
    "section": "",
    "text": "Using Machine Learning to Predict Diabetes\n\n\n\n\n\n\nR\n\n\nMachine Learning\n\n\nHealth\n\n\n\n\n\n\n\n\n\nInvalid Date\n\n\nEdward B. Quinn, PhD, MPH\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "sql_projects.html",
    "href": "sql_projects.html",
    "title": "SQL",
    "section": "",
    "text": "First SQL project\n\n\n\n\n\n\nSQL\n\n\n\n\n\n\n\n\n\nJul 30, 2023\n\n\nEdward B. Quinn, PhD, MPH\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "r_projects/first_post/index.html",
    "href": "r_projects/first_post/index.html",
    "title": "Using Machine Learning to Predict Diabetes",
    "section": "",
    "text": "Code# Some text"
  },
  {
    "objectID": "r_projects/r_machine_learning/index.html",
    "href": "r_projects/r_machine_learning/index.html",
    "title": "Using Machine Learning to Predict Diabetes",
    "section": "",
    "text": "Introduction\nOne of the most exciting applications of machine learning is in the prediction of disease states. Here, I demonstrate the use of a new modeling framework in R called tidymodels to compare multiple different types of machine learning models in their prediction of diabetes.\nThe Data\nThe data come from the National Institute of Diabetes Digestive and Kidney Diseases (Smith et al. 1988). There are 768 Pima Indian women included in the data set. Here’s a list of the variables:\n\nPregnancies - Number of pregnancies\nGlucose - Plasma glucose in mg/dl two hours after an oral glucose tolerance test\nBloodPressure - Diastolic blood pressure in mm Hg\nSkinThickness - Triceps skinfold thickness; a measure of body fat\nInsulin - Two hour serum insulin\nBMI - Body mass index\nDiabetesPedigreeFunction - A measure of family history of diabetes\nAge - Measured in years\nOutcome - An indicator variable for diabetes diagnosis\nExploratory Data Analysis\nLet’s load our libraries.\n\nCodesuppressPackageStartupMessages(library(tidyverse))\nsuppressPackageStartupMessages(library(tidymodels))\nsuppressPackageStartupMessages(library(RCurl))\nsuppressPackageStartupMessages(library(GGally))\nsuppressPackageStartupMessages(library(DT))\nsuppressPackageStartupMessages(library(gt))\nsuppressPackageStartupMessages(library(here))\n\n# Deal with conflicting function names across packages:\ntidymodels_prefer()\n\n\nRead in the data and take a look at the numbers in Table 1. A .csv file containing the data can be downloaded here.\n\nCodedf &lt;- read_csv(here(\"r_projects/r_machine_learning/diabetes.csv\"))\n\ndatatable(df)\n\n\nTable 1: Raw Data.\n\n\n\n\n\n\n\n\n\n\nIt is clear clicking on the filtering icons next to each variable name that there are some impossible values. For example, there are people with a BMI of zero. It is likely that missing values are encoded with a zero, so let’s set values of zero for the variables Glucose, BloodPressure, Insulin, BMI, and SkinThickness equal to NA to indicate missingness.\n\nCodedf &lt;- df |&gt; \n  mutate(across(c(Glucose,\n                BloodPressure,\n                Insulin,\n                BMI,\n                SkinThickness), ~na_if(.,0)))\n\n\nHow many missing values do we have in our dataset (Table 2)?\n\nCodedf |&gt; \n  summarise(across(everything(), ~ sum(is.na(.x)))) |&gt; \n  pivot_longer(everything(), values_to = \"number of missing values\") |&gt; \n  mutate(`percent missing` = `number of missing values`/nrow(df)) |&gt; \n  mutate(across(c(`percent missing`), ~round(.x*100, digits = 1))) |&gt; \n  datatable()\n\n\nTable 2: Number of Missing Values.\n\n\n\n\n\n\n\n\n\nSome columns have very few missing values, such as Glucose, while others, such as Insulin, have a very high proportion of missing values. Predictors typically cannot have missing values in machine learning applications, so we will need to estimate these missing values in our analysis pipeline.\nLet’s take a look at some summary statistics for our data in Table 3.\n\nCode# The sample n column is broken.\n\n# We also need a column counting missingness.\n\ndf |&gt; \n  summarise(across(colnames(df), .fns = \n                     list(n = ~n(),\n                          Mean = ~mean(.x, na.rm = TRUE),\n                          Median = ~median(.x, na.rm = TRUE),\n                          SD = ~sd(.x, na.rm = TRUE),\n                          Min = ~min(.x, na.rm = TRUE),\n                          Max = ~max(.x, na.rm = TRUE),\n                          q25 = ~quantile(.x, 0.25, na.rm = TRUE), \n                          q75 = ~quantile(.x, 0.75, na.rm = TRUE)\n                     ))) |&gt;  \n  pivot_longer(everything(), names_sep = \"_\", names_to = c(\"variable\", \".value\")) |&gt; \n  mutate(across(where(is.numeric), .fns = ~round(.x, digits = 1))) |&gt; \n  datatable()\n\n\nTable 3: Descriptive Statistics.\n\n\n\n\n\n\n\n\n\nAlso, note that the outcome is encoded as 0 (no diabetes) and 1 (diabetes). Let’s create an additional factor variable for the outcome. This will facilitate data visualization.\n\nCodedf &lt;- df |&gt; \n  mutate(Diagnosis = factor(Outcome, levels = c(0,1),\n                          labels = c(\"No Diabetes\",\"Diabetes\")))\n\n\nIt is always a good idea to visualize the data as part of exploratory data analysis (Figure 1).\n\nCodedf |&gt;\n  # Don't need the \"Outcome\" column right now, use \"Diagnosis\" instead\n  select(-Outcome) |&gt;\n  ggpairs(mapping = aes(color = Diagnosis, fill = Diagnosis)) +\n  scale_color_brewer(type = \"qual\",\n                     palette = \"Accent\") +\n  scale_fill_brewer(type = \"qual\",\n                     palette = \"Accent\") +\n  theme_bw()\n\n\n\n\n\n\nFigure 1: Pairs plot for all variables in data set.\n\n\n\n\n\n\n\nReferences\n\nSmith, Jack W., J. E. Everhart, W. C. Dickson, W. C. Knowler, and R. S. Johannes. 1988. “Using the ADAP Learning Algorithm to Forecast the Onset of Diabetes Mellitus.” Proceedings of the Annual Symposium on Computer Application in Medical Care, November, 261–65. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2245318/."
  },
  {
    "objectID": "machine_learning.html",
    "href": "machine_learning.html",
    "title": "Machine Learning",
    "section": "",
    "text": "Using Machine Learning to Predict Diabetes\n\n\n\n\n\n\nR\n\n\nMachine Learning\n\n\nHealth\n\n\n\n\n\n\n\n\n\nDec 2, 2023\n\n\nEdward B. Quinn, PhD, MPH\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "data_visualization.html",
    "href": "data_visualization.html",
    "title": "Data Visualization",
    "section": "",
    "text": "Progress in Public Health\n\n\n\n\n\n\nData Visualization\n\n\nR\n\n\n\n\n\n\n\n\n\nDec 17, 2023\n\n\nEdward B. Quinn, PhD, MPH\n\n\n\n\n\n\n\n\n\n\n\n\nData Visualization\n\n\n\n\n\n\nData Visualization\n\n\n\n\n\n\n\n\n\nJul 30, 2023\n\n\nEdward B. Quinn, PhD, MPH\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "database_management.html",
    "href": "database_management.html",
    "title": "Database Management",
    "section": "",
    "text": "Interactive-sql Example\n\n\nRun SQL Interactively from HTML Documents Made with Quarto\n\n\n\n\n\n\n\n\nDec 3, 2023\n\n\nShafayet Khan Shafee\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "machine_learning/index.html",
    "href": "machine_learning/index.html",
    "title": "Using Machine Learning to Predict Diabetes",
    "section": "",
    "text": "Introduction\nOne of the most exciting applications of machine learning is in the prediction of disease states. Here, I build a random forest classifier using a modeling framework in R called tidymodels. The random forest model will be tuned to predict diabetes diagnosis within five years.\nThe Data\nThe data come from the National Institute of Diabetes Digestive and Kidney Diseases (Smith et al. 1988). There are 768 Pima Indian women included in the data set. Here’s a list of the variables:\n\nPregnancies - Number of pregnancies\nGlucose - Plasma glucose in mg/dl two hours after an oral glucose tolerance test\nBloodPressure - Diastolic blood pressure in mm Hg\nSkinThickness - Triceps skinfold thickness; a measure of body fat\nInsulin - Two hour serum insulin\nBMI - Body mass index\nDiabetesPedigreeFunction - A measure of family history of diabetes\nAge - Measured in years\nOutcome - An indicator variable for diabetes diagnosis\nExploratory Data Analysis\nLet’s load our libraries.\n\nCodesuppressPackageStartupMessages(library(tidyverse))\nsuppressPackageStartupMessages(library(tidymodels))\nsuppressPackageStartupMessages(library(RCurl))\nsuppressPackageStartupMessages(library(GGally))\nsuppressPackageStartupMessages(library(DT))\nsuppressPackageStartupMessages(library(gt))\nsuppressPackageStartupMessages(library(here))\n\n# Deal with conflicting function names across packages:\ntidymodels_prefer()\n\n\nRead in the data and take a look at the numbers in Table 1. A .csv file containing the data can be downloaded here.\n\nCodedf &lt;- read_csv(here(\"machine_learning/diabetes.csv\"))\n\ndatatable(df)\n\n\nTable 1: Raw Data.\n\n\n\n\n\n\n\n\n\n\nIt is clear clicking on the filtering icons next to each variable name that there are some impossible values. For example, there are people with a BMI of zero. It is likely that missing values are encoded with a zero, so let’s set values of zero for the variables Glucose, BloodPressure, Insulin, BMI, and SkinThickness equal to NA to indicate missingness.\n\nCodedf &lt;- df |&gt; \n  mutate(across(c(Glucose,\n                BloodPressure,\n                Insulin,\n                BMI,\n                SkinThickness), ~na_if(.,0)))\n\n\nHow many missing values do we have in our dataset (Table 2)?\n\nCodedf |&gt; \n  summarise(across(everything(), ~ sum(is.na(.x)))) |&gt; \n  pivot_longer(everything(), values_to = \"number of missing values\") |&gt; \n  mutate(`percent missing` = `number of missing values`/nrow(df)) |&gt; \n  mutate(across(c(`percent missing`), ~round(.x*100, digits = 1))) |&gt; \n  datatable()\n\n\nTable 2: Number of Missing Values.\n\n\n\n\n\n\n\n\n\nSome columns have very few missing values, such as Glucose, while others, such as Insulin, have a very high proportion of missing values. Predictors typically cannot have missing values in machine learning applications, so we will need to estimate these missing values in our analysis pipeline.\nLet’s take a look at some summary statistics for our data in Table 3.\n\nCodedf |&gt; \n  summarise(across(colnames(df), .fns = \n                     list(n = ~n(),\n                          Mean = ~mean(.x, na.rm = TRUE),\n                          Median = ~median(.x, na.rm = TRUE),\n                          SD = ~sd(.x, na.rm = TRUE),\n                          Min = ~min(.x, na.rm = TRUE),\n                          Max = ~max(.x, na.rm = TRUE),\n                          q25 = ~quantile(.x, 0.25, na.rm = TRUE), \n                          q75 = ~quantile(.x, 0.75, na.rm = TRUE)\n                     ))) |&gt;  \n  pivot_longer(everything(), names_sep = \"_\", names_to = c(\"variable\", \".value\")) |&gt; \n  mutate(across(where(is.numeric), .fns = ~round(.x, digits = 1))) |&gt; \n  datatable()\n\n\nTable 3: Descriptive Statistics.\n\n\n\n\n\n\n\n\n\nAlso, note that the outcome is encoded as 0 (no diabetes) and 1 (diabetes). Let’s create an additional factor variable for the outcome. This will facilitate data visualization.\n\nCodedf &lt;- df |&gt; \n  mutate(Diagnosis = factor(Outcome, levels = c(0,1),\n                          labels = c(\"No Diabetes\",\"Diabetes\")))\n\n\nIt is always a good idea to visualize the data as part of exploratory data analysis (Figure 1).\n\nCodedf |&gt;\n  # Don't need the \"Outcome\" column right now, use \"Diagnosis\" instead\n  select(-Outcome) |&gt;\n  ggpairs(mapping = aes(color = Diagnosis, fill = Diagnosis)) +\n  scale_color_brewer(type = \"qual\",\n                     palette = \"Accent\") +\n  scale_fill_brewer(type = \"qual\",\n                     palette = \"Accent\") +\n  theme_bw()\n\n\n\n\n\n\nFigure 1: Pairs plot for all variables in data set.\n\n\n\n\nNote the differences in our predictors by Diagnosis, most clearly illustrated in the box plots to the right and the histograms in the bottom two rows. This indicates that our predictors may be useful in predicting onset of diabetes.\nMachine Learning\nThe following code will split the data into training and test sets, and then create a {tidymodels} workflow.\n\nCodeset.seed(456)\n\ndf_split &lt;- initial_split(data = df, prop = 0.75, strata = Diagnosis)\n\ndf_train &lt;- training(df_split)\n\ndf_test &lt;- testing(df_split)\n\n# Create a model\nrf_model &lt;- \n  rand_forest(mtry = 5, min_n = 40, trees = 1000) |&gt; \n  set_engine(\"ranger\") |&gt; \n  set_mode(\"classification\")\n\n# Create a recipe\nrf_recipe &lt;-\n  recipe(Diagnosis ~ Pregnancies + Glucose + BloodPressure + SkinThickness +\n                Insulin + BMI + DiabetesPedigreeFunction + Age, \n         data = df_train) |&gt; \n  step_impute_knn(Insulin,Glucose,BloodPressure,SkinThickness,BMI,\n                  DiabetesPedigreeFunction,Age) |&gt; \n  step_normalize(all_numeric_predictors())\n\n# Create a workflow\nset.seed(456)\nrf_workflow &lt;-\n  workflow() |&gt; \n  add_model(rf_model) |&gt; \n  add_recipe(rf_recipe)\n\n\nrf_fit &lt;- \n  fit(rf_workflow, df_train)\n\n# Predict outcomes for the test set using the trained model\ndf_test_res &lt;- predict(rf_fit, new_data = df_test |&gt; select(-Outcome))\n\n# Bind predictions to observed data for the test set\ndf_res &lt;- bind_cols(df_test_res, df_test |&gt;  select(Diagnosis))\n\n# Get the accuracy\naccuracy(df_res, truth = Diagnosis, estimate = .pred_class)\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.802\n\n\nOur accuracy is 80.2%. This an improvement over the simplest model, which would consist of guessing that no one will develop diabetes. The simple model would have 65.1% accuracy, so our first pass at a random forest model does represent an improvement in accuracy over the simple model. One thing we need to check is the stability of our measure of accuracy, which could be sensitive to the random seed we used. Let’s set up 5-fold cross validation (repeated 5 times) to get a more stable estimate of the accuracy of the random forest model.\n\nCodeset.seed(456)\ndf_folds &lt;- vfold_cv(df_train, v = 5, repeats = 5, strata = Diagnosis)\ndf_folds\n\n#  5-fold cross-validation repeated 5 times using stratification \n# A tibble: 25 × 3\n   splits            id      id2  \n   &lt;list&gt;            &lt;chr&gt;   &lt;chr&gt;\n 1 &lt;split [460/116]&gt; Repeat1 Fold1\n 2 &lt;split [461/115]&gt; Repeat1 Fold2\n 3 &lt;split [461/115]&gt; Repeat1 Fold3\n 4 &lt;split [461/115]&gt; Repeat1 Fold4\n 5 &lt;split [461/115]&gt; Repeat1 Fold5\n 6 &lt;split [460/116]&gt; Repeat2 Fold1\n 7 &lt;split [461/115]&gt; Repeat2 Fold2\n 8 &lt;split [461/115]&gt; Repeat2 Fold3\n 9 &lt;split [461/115]&gt; Repeat2 Fold4\n10 &lt;split [461/115]&gt; Repeat2 Fold5\n# ℹ 15 more rows\n\nCodeset.seed(456)\nrf_cv_fit &lt;- \n  fit_resamples(rf_workflow, df_folds)\n\nWarning: package 'ranger' was built under R version 4.3.2\n\nCodecollect_metrics(rf_cv_fit)\n\n# A tibble: 2 × 6\n  .metric  .estimator  mean     n std_err .config             \n  &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy binary     0.758    25 0.00548 Preprocessor1_Model1\n2 roc_auc  binary     0.817    25 0.00729 Preprocessor1_Model1\n\n\nCross validation suggests that a more stable estimate of the accuracy of our model would be 75.8%, which is still an improvement over guessing that no one will be diagnosed with diabetes within the next five years.\nWhy the drop in accuracy? This may be due to the necessarily small sample sizes in the analysis folds used in each cross validation iteration.\nWhat can we do to improve the accuracy of our model? There are several parameters of a random forest model that can be tuned, including mtry, trees, and min_n. Let’s try tuning to see if we can improve upon 75.8% accuracy.\n\nCode# Create a model\nrf_model_tune &lt;- \n  rand_forest(mtry = tune(), min_n = tune(), trees = tune()) |&gt; \n  set_engine(\"ranger\") |&gt; \n  set_mode(\"classification\")\n\n# Create a workflow\nset.seed(456)\nrf_workflow_tune &lt;-\n  workflow() |&gt; \n  add_model(rf_model_tune) |&gt; \n  add_recipe(rf_recipe)\n\n\n# All operating systems\nsuppressPackageStartupMessages(library(doParallel))\nsuppressPackageStartupMessages(library(finetune))\n\nWarning: package 'finetune' was built under R version 4.3.2\n\nCodeset.seed(456)\n\n# Create a cluster object and then register: \ncl &lt;- makePSOCKcluster(4)\nregisterDoParallel(cl)\n\nsystem.time(\nrf_tune &lt;-\n  tune_race_anova(rf_workflow_tune,\n            resamples = df_folds,\n            grid = 60)\n)\n\ni Creating pre-processing data to finalize unknown parameter: mtry\n\n\n   user  system elapsed \n  14.08    0.44  205.00 \n\nCodestopCluster(cl)\n\n\nrf_tune |&gt; \n  show_best(metric = \"accuracy\")\n\n# A tibble: 5 × 9\n   mtry trees min_n .metric  .estimator  mean     n std_err .config             \n  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1     2  1458    36 accuracy binary     0.760    25 0.00491 Preprocessor1_Model…\n2     2  1141    23 accuracy binary     0.757    25 0.00503 Preprocessor1_Model…\n3     1  1337    30 accuracy binary     0.757    25 0.00522 Preprocessor1_Model…\n4     1  1483    24 accuracy binary     0.755    25 0.00540 Preprocessor1_Model…\n5     1  1650    14 accuracy binary     0.755    25 0.00555 Preprocessor1_Model…\n\n\nNow let’s take the optimal combination of tuning parameters and retrain the model on the entire training data set.\n\nCode# the last model\nlast_rf_mod &lt;- \n  rand_forest(mtry = 2, min_n = 36, trees = 1458) |&gt;  \n  set_engine(\"ranger\", importance = \"impurity\") |&gt; \n  set_mode(\"classification\")\n\n# the last workflow\nlast_rf_workflow &lt;- \n  rf_workflow_tune |&gt;  \n  update_model(last_rf_mod)\n\n# the last fit\nset.seed(456)\nlast_rf_fit &lt;- \n  last_rf_workflow |&gt; \n  last_fit(df_split)\n\nlast_rf_fit |&gt; \n  collect_metrics()\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy binary         0.786 Preprocessor1_Model1\n2 roc_auc  binary         0.867 Preprocessor1_Model1\n\nCodelast_rf_fit |&gt; \n  collect_predictions() |&gt; \n  roc_curve(Diagnosis, `.pred_No Diabetes`) |&gt; \n  autoplot()\n\n\n\n\nOur accuracy is now 78.6%. Which variables are most important in predicting onset of diabetes within the next five years?\n\nCodesuppressPackageStartupMessages(library(vip))\n\nWarning: package 'vip' was built under R version 4.3.2\n\nCodelast_rf_fit |&gt; \n  extract_fit_parsnip() |&gt; \n  vip(aesthetics = list(fill = \"midnightblue\", alpha = 0.6)) +\n  theme_classic()\n\n\n\n\nNot surprisingly, Glucose is the most important variable in predicting onset of diabetes. That’s reassuring since diabetes is diagnosed using glucose levels!\nNext Steps\nThis is a very rough first pass at predicting onset of diabetes using a random forest machine learning model. We could try to improve accuracy in the test set with additional feature engineering, tinkering with preprocessing steps, and using expanded grids when tuning parameters. That’s all for now!\n\n\n\nReferences\n\nSmith, Jack W., J. E. Everhart, W. C. Dickson, W. C. Knowler, and R. S. Johannes. 1988. “Using the ADAP Learning Algorithm to Forecast the Onset of Diabetes Mellitus.” Proceedings of the Annual Symposium on Computer Application in Medical Care, November, 261–65. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2245318/."
  },
  {
    "objectID": "dashboards/index.html",
    "href": "dashboards/index.html",
    "title": "R-shinylive-demo",
    "section": "",
    "text": "#| standalone: true\n#| viewerHeight: 600\nlibrary(shiny)\nlibrary(bslib)\n\n# Define UI for app that draws a histogram ----\nui &lt;- page_sidebar(\n  sidebar = sidebar(open = \"open\",\n    numericInput(\"n\", \"Sample count\", 100),\n    checkboxInput(\"pause\", \"Pause\", FALSE),\n  ),\n  plotOutput(\"plot\", width=1100)\n)\n\nserver &lt;- function(input, output, session) {\n  data &lt;- reactive({\n    input$resample\n    if (!isTRUE(input$pause)) {\n      invalidateLater(1000)\n    }\n    rnorm(input$n)\n  })\n  \n  output$plot &lt;- renderPlot({\n    hist(data(),\n      breaks = 40,\n      xlim = c(-2, 2),\n      ylim = c(0, 1),\n      lty = \"blank\",\n      xlab = \"value\",\n      freq = FALSE,\n      main = \"\"\n    )\n    \n    x &lt;- seq(from = -2, to = 2, length.out = 500)\n    y &lt;- dnorm(x)\n    lines(x, y, lwd=1.5)\n    \n    lwd &lt;- 5\n    abline(v=0, col=\"red\", lwd=lwd, lty=2)\n    abline(v=mean(data()), col=\"blue\", lwd=lwd, lty=1)\n\n    legend(legend = c(\"Normal\", \"Mean\", \"Sample mean\"),\n      col = c(\"black\", \"red\", \"blue\"),\n      lty = c(1, 2, 1),\n      lwd = c(1, lwd, lwd),\n      x = 1,\n      y = 0.9\n    )\n  }, res=140)\n}\n\n# Create Shiny app ----\nshinyApp(ui = ui, server = server)"
  },
  {
    "objectID": "dashboards.html",
    "href": "dashboards.html",
    "title": "Machine Learning",
    "section": "",
    "text": "Shinylive in Quarto example\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR-shinylive-demo\n\n\n\n\n\n\nDashboards\n\n\n\n\n\n\n\n\n\nJul 30, 2023\n\n\nEdward B. Quinn, PhD, MPH\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "machine_learning/test.html",
    "href": "machine_learning/test.html",
    "title": "test",
    "section": "",
    "text": "Introduction"
  },
  {
    "objectID": "machine_learning/machine_learning.html",
    "href": "machine_learning/machine_learning.html",
    "title": "Machine Learning",
    "section": "",
    "text": "Using Machine Learning to Predict Diabetes\n\n\n\n\n\n\nR\n\n\nMachine Learning\n\n\nHealth\n\n\n\n\n\n\n\n\n\nInvalid Date\n\n\nEdward B. Quinn, PhD, MPH\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "machine_learning/predict_diabetes/index.html",
    "href": "machine_learning/predict_diabetes/index.html",
    "title": "Using Machine Learning to Predict Diabetes",
    "section": "",
    "text": "Introduction\nOne of the most exciting applications of machine learning is in the prediction of disease states. Here, I build a random forest classifier using a modeling framework in R called tidymodels. The random forest model will be tuned to predict diabetes diagnosis within five years.\nThe Data\nThe data come from the National Institute of Diabetes Digestive and Kidney Diseases (Smith et al. 1988). There are 768 Pima Indian women included in the data set. Here’s a list of the variables:\n\nPregnancies - Number of pregnancies\nGlucose - Plasma glucose in mg/dl two hours after an oral glucose tolerance test\nBloodPressure - Diastolic blood pressure in mm Hg\nSkinThickness - Triceps skinfold thickness; a measure of body fat\nInsulin - Two hour serum insulin\nBMI - Body mass index\nDiabetesPedigreeFunction - A measure of family history of diabetes\nAge - Measured in years\nOutcome - An indicator variable for diabetes diagnosis\nExploratory Data Analysis\nLet’s load our libraries.\n\nCodesuppressPackageStartupMessages(library(tidyverse))\nsuppressPackageStartupMessages(library(tidymodels))\nsuppressPackageStartupMessages(library(RCurl))\nsuppressPackageStartupMessages(library(GGally))\nsuppressPackageStartupMessages(library(DT))\nsuppressPackageStartupMessages(library(gt))\nsuppressPackageStartupMessages(library(here))\n\n# Deal with conflicting function names across packages:\ntidymodels_prefer()\n\n\nRead in the data and take a look at the numbers in Table 1. A .csv file containing the data can be downloaded here.\n\nCodedf &lt;- read_csv(here(\"machine_learning/predict_diabetes/diabetes.csv\"))\n\ndatatable(df)\n\n\nTable 1: Raw Data.\n\n\n\n\n\n\n\n\n\n\nIt is clear clicking on the filtering icons next to each variable name that there are some impossible values. For example, there are people with a BMI of zero. It is likely that missing values are encoded with a zero, so let’s set values of zero for the variables Glucose, BloodPressure, Insulin, BMI, and SkinThickness equal to NA to indicate missingness.\n\nCodedf &lt;- df |&gt; \n  mutate(across(c(Glucose,\n                BloodPressure,\n                Insulin,\n                BMI,\n                SkinThickness), ~na_if(.,0)))\n\n\nHow many missing values do we have in our dataset (Table 2)?\n\nCodedf |&gt; \n  summarise(across(everything(), ~ sum(is.na(.x)))) |&gt; \n  pivot_longer(everything(), values_to = \"number of missing values\") |&gt; \n  mutate(`percent missing` = `number of missing values`/nrow(df)) |&gt; \n  mutate(across(c(`percent missing`), ~round(.x*100, digits = 1))) |&gt; \n  datatable()\n\n\nTable 2: Number of Missing Values.\n\n\n\n\n\n\n\n\n\nSome columns have very few missing values, such as Glucose, while others, such as Insulin, have a very high proportion of missing values. Predictors typically cannot have missing values in machine learning applications, so we will need to estimate these missing values in our analysis pipeline.\nLet’s take a look at some summary statistics for our data in Table 3.\n\nCodedf |&gt; \n  summarise(across(colnames(df), .fns = \n                     list(n = ~n(),\n                          Mean = ~mean(.x, na.rm = TRUE),\n                          Median = ~median(.x, na.rm = TRUE),\n                          SD = ~sd(.x, na.rm = TRUE),\n                          Min = ~min(.x, na.rm = TRUE),\n                          Max = ~max(.x, na.rm = TRUE),\n                          q25 = ~quantile(.x, 0.25, na.rm = TRUE), \n                          q75 = ~quantile(.x, 0.75, na.rm = TRUE)\n                     ))) |&gt;  \n  pivot_longer(everything(), names_sep = \"_\", names_to = c(\"variable\", \".value\")) |&gt; \n  mutate(across(where(is.numeric), .fns = ~round(.x, digits = 1))) |&gt; \n  datatable()\n\n\nTable 3: Descriptive Statistics.\n\n\n\n\n\n\n\n\n\nAlso, note that the outcome is encoded as 0 (no diabetes) and 1 (diabetes). Let’s create an additional factor variable for the outcome. This will facilitate data visualization.\n\nCodedf &lt;- df |&gt; \n  mutate(Diagnosis = factor(Outcome, levels = c(0,1),\n                          labels = c(\"No Diabetes\",\"Diabetes\")))\n\n\nIt is always a good idea to visualize the data as part of exploratory data analysis (Figure 1).\n\nCodedf |&gt;\n  # Don't need the \"Outcome\" column right now, use \"Diagnosis\" instead\n  select(-Outcome) |&gt;\n  ggpairs(mapping = aes(color = Diagnosis, fill = Diagnosis)) +\n  scale_color_brewer(type = \"qual\",\n                     palette = \"Accent\") +\n  scale_fill_brewer(type = \"qual\",\n                     palette = \"Accent\") +\n  theme_bw()\n\n\n\n\n\n\nFigure 1: Pairs plot for all variables in data set.\n\n\n\n\nNote the differences in our predictors by Diagnosis, most clearly illustrated in the box plots to the right and the histograms in the bottom two rows. This indicates that our predictors may be useful in predicting onset of diabetes.\nMachine Learning\nThe following code will split the data into training and test sets, and then create a {tidymodels} workflow.\n\nCodeset.seed(456)\n\ndf_split &lt;- initial_split(data = df, prop = 0.75, strata = Diagnosis)\n\ndf_train &lt;- training(df_split)\n\ndf_test &lt;- testing(df_split)\n\n# Create a model\nrf_model &lt;- \n  rand_forest(mtry = 5, min_n = 40, trees = 1000) |&gt; \n  set_engine(\"ranger\") |&gt; \n  set_mode(\"classification\")\n\n# Create a recipe\nrf_recipe &lt;-\n  recipe(Diagnosis ~ Pregnancies + Glucose + BloodPressure + SkinThickness +\n                Insulin + BMI + DiabetesPedigreeFunction + Age, \n         data = df_train) |&gt; \n  step_impute_knn(Insulin,Glucose,BloodPressure,SkinThickness,BMI,\n                  DiabetesPedigreeFunction,Age) |&gt; \n  step_normalize(all_numeric_predictors())\n\n# Create a workflow\nset.seed(456)\nrf_workflow &lt;-\n  workflow() |&gt; \n  add_model(rf_model) |&gt; \n  add_recipe(rf_recipe)\n\n\nrf_fit &lt;- \n  fit(rf_workflow, df_train)\n\n# Predict outcomes for the test set using the trained model\ndf_test_res &lt;- predict(rf_fit, new_data = df_test |&gt; select(-Outcome))\n\n# Bind predictions to observed data for the test set\ndf_res &lt;- bind_cols(df_test_res, df_test |&gt;  select(Diagnosis))\n\n# Get the accuracy\naccuracy(df_res, truth = Diagnosis, estimate = .pred_class)\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.802\n\n\nOur accuracy is 80.2%. This an improvement over the simplest model, which would consist of guessing that no one will develop diabetes. The simple model would have 65.1% accuracy, so our first pass at a random forest model does represent an improvement in accuracy over the simple model. One thing we need to check is the stability of our measure of accuracy, which could be sensitive to the random seed we used. Let’s set up 5-fold cross validation (repeated 5 times) to get a more stable estimate of the accuracy of the random forest model.\n\nCodeset.seed(456)\ndf_folds &lt;- vfold_cv(df_train, v = 5, repeats = 5, strata = Diagnosis)\ndf_folds\n\n#  5-fold cross-validation repeated 5 times using stratification \n# A tibble: 25 × 3\n   splits            id      id2  \n   &lt;list&gt;            &lt;chr&gt;   &lt;chr&gt;\n 1 &lt;split [460/116]&gt; Repeat1 Fold1\n 2 &lt;split [461/115]&gt; Repeat1 Fold2\n 3 &lt;split [461/115]&gt; Repeat1 Fold3\n 4 &lt;split [461/115]&gt; Repeat1 Fold4\n 5 &lt;split [461/115]&gt; Repeat1 Fold5\n 6 &lt;split [460/116]&gt; Repeat2 Fold1\n 7 &lt;split [461/115]&gt; Repeat2 Fold2\n 8 &lt;split [461/115]&gt; Repeat2 Fold3\n 9 &lt;split [461/115]&gt; Repeat2 Fold4\n10 &lt;split [461/115]&gt; Repeat2 Fold5\n# ℹ 15 more rows\n\nCodeset.seed(456)\nrf_cv_fit &lt;- \n  fit_resamples(rf_workflow, df_folds)\n\nWarning: package 'ranger' was built under R version 4.3.2\n\nCodecollect_metrics(rf_cv_fit)\n\n# A tibble: 2 × 6\n  .metric  .estimator  mean     n std_err .config             \n  &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy binary     0.758    25 0.00548 Preprocessor1_Model1\n2 roc_auc  binary     0.817    25 0.00729 Preprocessor1_Model1\n\n\nCross validation suggests that a more stable estimate of the accuracy of our model would be 75.8%, which is still an improvement over guessing that no one will be diagnosed with diabetes within the next five years.\nWhy the drop in accuracy? This may be due to the necessarily small sample sizes in the analysis folds used in each cross validation iteration.\nWhat can we do to improve the accuracy of our model? There are several parameters of a random forest model that can be tuned, including mtry, trees, and min_n. Let’s try tuning to see if we can improve upon 75.8% accuracy.\n\nCode# Create a model\nrf_model_tune &lt;- \n  rand_forest(mtry = tune(), min_n = tune(), trees = tune()) |&gt; \n  set_engine(\"ranger\") |&gt; \n  set_mode(\"classification\")\n\n# Create a workflow\nset.seed(456)\nrf_workflow_tune &lt;-\n  workflow() |&gt; \n  add_model(rf_model_tune) |&gt; \n  add_recipe(rf_recipe)\n\n\n# All operating systems\nsuppressPackageStartupMessages(library(doParallel))\nsuppressPackageStartupMessages(library(finetune))\n\nWarning: package 'finetune' was built under R version 4.3.2\n\nCodeset.seed(456)\n\n# Create a cluster object and then register: \ncl &lt;- makePSOCKcluster(4)\nregisterDoParallel(cl)\n\nsystem.time(\nrf_tune &lt;-\n  tune_race_anova(rf_workflow_tune,\n            resamples = df_folds,\n            grid = 60)\n)\n\ni Creating pre-processing data to finalize unknown parameter: mtry\n\n\n   user  system elapsed \n   9.44    0.41  140.06 \n\nCodestopCluster(cl)\n\n\nrf_tune |&gt; \n  show_best(metric = \"accuracy\")\n\n# A tibble: 5 × 9\n   mtry trees min_n .metric  .estimator  mean     n std_err .config             \n  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1     2  1458    36 accuracy binary     0.760    25 0.00491 Preprocessor1_Model…\n2     2  1141    23 accuracy binary     0.757    25 0.00503 Preprocessor1_Model…\n3     1  1337    30 accuracy binary     0.757    25 0.00522 Preprocessor1_Model…\n4     1  1483    24 accuracy binary     0.755    25 0.00540 Preprocessor1_Model…\n5     1  1650    14 accuracy binary     0.755    25 0.00555 Preprocessor1_Model…\n\n\nNow let’s take the optimal combination of tuning parameters and retrain the model on the entire training data set.\n\nCode# the last model\nlast_rf_mod &lt;- \n  rand_forest(mtry = 2, min_n = 36, trees = 1458) |&gt;  \n  set_engine(\"ranger\", importance = \"impurity\") |&gt; \n  set_mode(\"classification\")\n\n# the last workflow\nlast_rf_workflow &lt;- \n  rf_workflow_tune |&gt;  \n  update_model(last_rf_mod)\n\n# the last fit\nset.seed(456)\nlast_rf_fit &lt;- \n  last_rf_workflow |&gt; \n  last_fit(df_split)\n\nlast_rf_fit |&gt; \n  collect_metrics()\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy binary         0.786 Preprocessor1_Model1\n2 roc_auc  binary         0.867 Preprocessor1_Model1\n\nCodelast_rf_fit |&gt; \n  collect_predictions() |&gt; \n  roc_curve(Diagnosis, `.pred_No Diabetes`) |&gt; \n  autoplot()\n\n\n\n\nOur accuracy is now 78.6%. Which variables are most important in predicting onset of diabetes within the next five years?\n\nCodesuppressPackageStartupMessages(library(vip))\n\nWarning: package 'vip' was built under R version 4.3.2\n\nCodelast_rf_fit |&gt; \n  extract_fit_parsnip() |&gt; \n  vip(aesthetics = list(fill = \"midnightblue\", alpha = 0.6)) +\n  theme_classic()\n\n\n\n\nNot surprisingly, Glucose is the most important variable in predicting onset of diabetes. That’s reassuring since diabetes is diagnosed using glucose levels!\nNext Steps\nThis is a very rough first pass at predicting onset of diabetes using a random forest machine learning model. We could try to improve accuracy in the test set with additional feature engineering, tinkering with preprocessing steps, and using expanded grids when tuning parameters. That’s all for now!\n\n\n\nReferences\n\nSmith, Jack W., J. E. Everhart, W. C. Dickson, W. C. Knowler, and R. S. Johannes. 1988. “Using the ADAP Learning Algorithm to Forecast the Onset of Diabetes Mellitus.” Proceedings of the Annual Symposium on Computer Application in Medical Care, November, 261–65. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2245318/."
  },
  {
    "objectID": "machine_learning/test/tested.html",
    "href": "machine_learning/test/tested.html",
    "title": "Data Science Portfolio",
    "section": "",
    "text": "test test"
  },
  {
    "objectID": "machine_learning/diabetes/index.html",
    "href": "machine_learning/diabetes/index.html",
    "title": "Using Machine Learning to Predict Diabetes",
    "section": "",
    "text": "Introduction\nOne of the most exciting applications of machine learning is in the prediction of disease states. Here, I build a random forest classifier using a modeling framework in R called tidymodels. The random forest model will be tuned to predict diabetes diagnosis within five years.\nThe Data\nThe data come from the National Institute of Diabetes Digestive and Kidney Diseases (Smith et al. 1988). There are 768 Pima Indian women included in the data set. Here’s a list of the variables:\n\nPregnancies - Number of pregnancies\nGlucose - Plasma glucose in mg/dl two hours after an oral glucose tolerance test\nBloodPressure - Diastolic blood pressure in mm Hg\nSkinThickness - Triceps skinfold thickness; a measure of body fat\nInsulin - Two hour serum insulin\nBMI - Body mass index\nDiabetesPedigreeFunction - A measure of family history of diabetes\nAge - Measured in years\nOutcome - An indicator variable for diabetes diagnosis\nExploratory Data Analysis\nLet’s load our libraries.\n\nCodesuppressPackageStartupMessages(library(tidyverse))\nsuppressPackageStartupMessages(library(tidymodels))\nsuppressPackageStartupMessages(library(RCurl))\nsuppressPackageStartupMessages(library(GGally))\nsuppressPackageStartupMessages(library(DT))\nsuppressPackageStartupMessages(library(gt))\n# All operating systems\nsuppressPackageStartupMessages(library(doParallel))\nsuppressPackageStartupMessages(library(finetune))\nsuppressPackageStartupMessages(library(vip))\nsuppressPackageStartupMessages(library(here))\n\n# Deal with conflicting function names across packages:\ntidymodels_prefer()\n\n\nRead in the data and take a look at the numbers in Table 1. A .csv file containing the data can be downloaded here.\n\nCodedf &lt;- read_csv(here(\"machine_learning/diabetes/diabetes.csv\"))\n\ndatatable(df)\n\n\nTable 1: Raw Data.\n\n\n\n\n\n\n\n\n\n\nIt is clear clicking on the filtering icons next to each variable name that there are some impossible values. For example, there are people with a BMI of zero. It is likely that missing values are encoded with a zero, so let’s set values of zero for the variables Glucose, BloodPressure, Insulin, BMI, and SkinThickness equal to NA to indicate missingness.\n\nCodedf &lt;- df |&gt; \n  mutate(across(c(Glucose,\n                BloodPressure,\n                Insulin,\n                BMI,\n                SkinThickness), ~na_if(.,0)))\n\n\nHow many missing values do we have in our dataset (Table 2)?\n\nCodedf |&gt; \n  summarise(across(everything(), ~ sum(is.na(.x)))) |&gt; \n  pivot_longer(everything(), values_to = \"number of missing values\") |&gt; \n  mutate(`percent missing` = `number of missing values`/nrow(df)) |&gt; \n  mutate(across(c(`percent missing`), ~round(.x*100, digits = 1))) |&gt; \n  datatable()\n\n\nTable 2: Number of Missing Values.\n\n\n\n\n\n\n\n\n\nSome columns have very few missing values, such as Glucose, while others, such as Insulin, have a very high proportion of missing values. Predictors typically cannot have missing values in machine learning applications, so we will need to estimate these missing values in our analysis pipeline.\nLet’s take a look at some summary statistics for our data in Table 3.\n\nCodedf |&gt; \n  summarise(across(colnames(df), .fns = \n                     list(n = ~n(),\n                          Mean = ~mean(.x, na.rm = TRUE),\n                          Median = ~median(.x, na.rm = TRUE),\n                          SD = ~sd(.x, na.rm = TRUE),\n                          Min = ~min(.x, na.rm = TRUE),\n                          Max = ~max(.x, na.rm = TRUE),\n                          q25 = ~quantile(.x, 0.25, na.rm = TRUE), \n                          q75 = ~quantile(.x, 0.75, na.rm = TRUE)\n                     ))) |&gt;  \n  pivot_longer(everything(), names_sep = \"_\", names_to = c(\"variable\", \".value\")) |&gt; \n  mutate(across(where(is.numeric), .fns = ~round(.x, digits = 1))) |&gt; \n  datatable()\n\n\nTable 3: Descriptive Statistics.\n\n\n\n\n\n\n\n\n\nAlso, note that the outcome is encoded as 0 (no diabetes) and 1 (diabetes). Let’s create an additional factor variable for the outcome. This will facilitate data visualization.\n\nCodedf &lt;- df |&gt; \n  mutate(Diagnosis = factor(Outcome, levels = c(0,1),\n                          labels = c(\"No Diabetes\",\"Diabetes\")))\n\n\nIt is always a good idea to visualize the data as part of exploratory data analysis (Figure 1). Correlations quantify the strength of linear relationships between the predictors, which may differ by outcome.\n\nCodedf |&gt;\n  # Don't need the \"Outcome\" column right now, use \"Diagnosis\" instead\n  select(-Outcome) |&gt;\n  ggpairs(mapping = aes(color = Diagnosis, fill = Diagnosis)) +\n  scale_color_brewer(type = \"qual\",\n                     palette = \"Accent\") +\n  scale_fill_brewer(type = \"qual\",\n                     palette = \"Accent\") +\n  theme_bw()\n\n\n\n\n\n\nFigure 1: Pairs plot for all variables in data set.\n\n\n\n\nNote the differences in our predictors by Diagnosis, most clearly illustrated in the box plots to the right and the histograms in the bottom two rows. This indicates that our predictors may be useful in predicting onset of diabetes.\nMachine Learning\nThe following code will:\n\nSplit the data into training and test sets\nCreate a tidymodels workflow by specifying a machine learning model and a preprocessing pipeline\nUse five-fold cross validation to train the model using a space-filling grid design for candidate tuning parameters\n\n\nCode# Step 1\nset.seed(456)\n\ndf_split &lt;- initial_split(data = df, prop = 0.75, strata = Diagnosis)\n\ndf_train &lt;- training(df_split)\n\ndf_test &lt;- testing(df_split)\n\n\n# Step 2\n\n# Create a model\nrf_model_tune &lt;- \n  rand_forest(mtry = tune(), min_n = tune(), trees = 1500) |&gt; \n  set_engine(\"ranger\") |&gt; \n  set_mode(\"classification\")\n\n# Create a recipe\nrf_recipe &lt;-\n  recipe(Diagnosis ~ Pregnancies + Glucose + BloodPressure + SkinThickness +\n                Insulin + BMI + DiabetesPedigreeFunction + Age, \n         data = df_train) |&gt; \n  step_impute_knn(Insulin,Glucose,BloodPressure,SkinThickness,BMI,\n                  DiabetesPedigreeFunction,Age) |&gt; \n  step_normalize(all_numeric_predictors())\n\n# Create a workflow\nset.seed(456)\nrf_workflow_tune &lt;-\n  workflow() |&gt; \n  add_model(rf_model_tune) |&gt; \n  add_recipe(rf_recipe)\n\n\n# Step 3\nset.seed(456)\ndf_folds &lt;- vfold_cv(df_train, v = 5, repeats = 5, strata = Diagnosis)\n\n\n\n\n# Train the model\nset.seed(456)\n\n# Create a cluster object and then register: \ncl &lt;- makePSOCKcluster(4)\nregisterDoParallel(cl)\n\nsystem.time(\nrf_tune &lt;-\n  tune_race_anova(rf_workflow_tune,\n            resamples = df_folds,\n            grid = 60)\n)\n\n   user  system elapsed \n   9.22    0.30  201.25 \n\nCodestopCluster(cl)\n\n\nWhat was the best combination of tuning parameters in our model training?\n\nCode# Extract the final model\nrf_tune |&gt; \n  show_best(metric = \"accuracy\") |&gt; \n  mutate(across(where(is.numeric), .fns = ~round(.x, digits = 3))) |&gt; \n  datatable()\n\n\n\n\n\n\nNow let’s take the optimal combination of tuning parameters and retrain the model on the entire training data set and then the test data set.\n\nCode# the last model\nlast_rf_mod &lt;- \n  rand_forest(mtry = 2, min_n = 21, trees = 1500) |&gt;  \n  set_engine(\"ranger\", importance = \"impurity\") |&gt; \n  set_mode(\"classification\")\n\n# the last workflow\nlast_rf_workflow &lt;- \n  rf_workflow_tune |&gt;  \n  update_model(last_rf_mod)\n\n# the last fit\nset.seed(456)\nlast_rf_fit &lt;- \n  last_rf_workflow |&gt; \n  last_fit(df_split)\n\n\n\nHow does the final model perform in our training data?\n\nCodeset.seed(456)\ntraining_set_predictions &lt;- \n  last_rf_workflow |&gt; \n  fit(data = df_train) |&gt; \n  predict(df_train)\n\n# Compare actual outcomes to predicted outcomes\ntraining_confusion_matrix &lt;- table(Actual = df_train$Diagnosis, Predicted = training_set_predictions$.pred_class)\n\n# Calculate accuracy\ntraining_accuracy &lt;- sum(diag(training_confusion_matrix)) / sum(training_confusion_matrix)\n\ncat(\"The accuracy of the final model on the training data is\",\n    paste(round(training_accuracy*100, digits = 2), \"%\", sep = \"\"))\n\nThe accuracy of the final model on the training data is 91.84%\n\n\n\nHow does our final model perform in our testing data?\n\nCodeset.seed(456)\ntesting_set_predictions &lt;- \n  last_rf_workflow |&gt; \n  fit(data = df_train) |&gt; \n  predict(df_test)\n\n# Compare actual outcomes to predicted outcomes\ntesting_confusion_matrix &lt;- table(Actual = df_test$Diagnosis, Predicted = testing_set_predictions$.pred_class)\n\n# Calculate accuracy\ntesting_accuracy &lt;- sum(diag(testing_confusion_matrix)) / sum(testing_confusion_matrix)\n\ncat(\"The accuracy of the final model on the testing data is\",\n    paste(round(testing_accuracy*100, digits = 2), \"%\", sep = \"\"))\n\nThe accuracy of the final model on the testing data is 78.65%\n\n\n\nWe can visualize the trade off between sensitivity and specificity using a ROC curve (Figure 2).\n\nCodelast_rf_fit |&gt;\n  collect_predictions() |&gt;\n  roc_curve(Diagnosis, `.pred_No Diabetes`) |&gt;\n  autoplot()\n\n\n\n\n\n\nFigure 2: Receiver Operating Characteristic Curve\n\n\n\n\n\nWhich variables are most important in predicting onset of diabetes within the next five years (Figure 3)?\n\nCodelast_rf_fit |&gt; \n  extract_fit_parsnip() |&gt; \n  vip(aesthetics = list(fill = \"midnightblue\", alpha = 0.6)) +\n  theme_classic()\n\n\n\n\n\n\nFigure 3: Variable Importance Bar Chart\n\n\n\n\nNot surprisingly, Glucose is the most important variable in predicting onset of diabetes. That’s reassuring since diabetes is diagnosed using glucose levels!\nNext Steps\nThis is a very rough first pass at predicting onset of diabetes using a random forest machine learning model. Moving forward, we could try to improve accuracy in the test set with additional feature engineering, tinkering with preprocessing steps, and using expanded grids when tuning parameters.\n\n\n\nReferences\n\nSmith, Jack W., J. E. Everhart, W. C. Dickson, W. C. Knowler, and R. S. Johannes. 1988. “Using the ADAP Learning Algorithm to Forecast the Onset of Diabetes Mellitus.” Proceedings of the Annual Symposium on Computer Application in Medical Care, November, 261–65. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2245318/."
  },
  {
    "objectID": "machine_learning/test/index.html",
    "href": "machine_learning/test/index.html",
    "title": "tester",
    "section": "",
    "text": "Introduction\nOne of the most exciting applications of machine learning is in the prediction of disease states. Here, I build a random forest classifier using a modeling framework in R called tidymodels. The random forest model will be tuned to predict diabetes diagnosis within five years.\nThe Data\nThe data come from the National Institute of Diabetes Digestive and Kidney Diseases [@smith1988]. There are 768 Pima Indian women included in the data set. Here’s a list of the variables:\n\nPregnancies - Number of pregnancies\nGlucose - Plasma glucose in mg/dl two hours after an oral glucose tolerance test\nBloodPressure - Diastolic blood pressure in mm Hg\nSkinThickness - Triceps skinfold thickness; a measure of body fat\nInsulin - Two hour serum insulin\nBMI - Body mass index\nDiabetesPedigreeFunction - A measure of family history of diabetes\nAge - Measured in years\nOutcome - An indicator variable for diabetes diagnosis\nExploratory Data Analysis\nLet’s load our libraries.\n\nCodesuppressPackageStartupMessages(library(tidyverse))\nsuppressPackageStartupMessages(library(RCurl))\nsuppressPackageStartupMessages(library(DT))\nsuppressPackageStartupMessages(library(here))\n\n\n\nCodedf &lt;- read_csv(here(\"machine_learning/test/diabetes.csv\"))\n\nRows: 768 Columns: 9\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (9): Pregnancies, Glucose, BloodPressure, SkinThickness, Insulin, BMI, D...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nCodedatatable(df)"
  },
  {
    "objectID": "database_management/sql_lite/index.html",
    "href": "database_management/sql_lite/index.html",
    "title": "Interactive-sql Example",
    "section": "",
    "text": "Here we will use a sample Database called HR that manages the HR data of the small businesses which is collected from www.sqltutorial.org. And to create the database, a SQLite script file was used when rendering the document. Read the extension docs for details."
  },
  {
    "objectID": "database_management/sql_lite/index.html#hr-sample-database",
    "href": "database_management/sql_lite/index.html#hr-sample-database",
    "title": "Interactive-sql Example",
    "section": "HR sample database",
    "text": "HR sample database\nThe following database diagram illustrates the HR sample database:\n\n\n\n\n\n\nFigure 1: ERD of HR database\n\n\n\nAnd now, you can run all sort of queries from the tables of the HR databases."
  },
  {
    "objectID": "database_management/sql_lite/index.html#editable-example",
    "href": "database_management/sql_lite/index.html#editable-example",
    "title": "Interactive-sql Example",
    "section": "Editable Example",
    "text": "Editable Example\n\nselect * from regions;"
  },
  {
    "objectID": "database_management/sql_lite/index.html#not-editable-example",
    "href": "database_management/sql_lite/index.html#not-editable-example",
    "title": "Interactive-sql Example",
    "section": "Not editable example",
    "text": "Not editable example\nYou can also create “not-editable” code chunk (that is, you simply can run the query but won’t be able to edit/modify it) for HR database. And to do this, just use another instance of database under the database key in the yaml with a different name and use the option editable: false. Then all the code chunk with that name as class will be in not-editable mode. View the source code of this document by clicking &lt;/&gt; Code on top-right corner, it will be more clear, what I am trying to say.\n\nselect * from employees;"
  },
  {
    "objectID": "data_visualization/index.html",
    "href": "data_visualization/index.html",
    "title": "Data Visualization",
    "section": "",
    "text": "Codeplot(sin(1:10))"
  },
  {
    "objectID": "data_visualization/map/index.html",
    "href": "data_visualization/map/index.html",
    "title": "Data Visualization",
    "section": "",
    "text": "Codelibrary(tidycensus)\n\n\ntidycensus::get_acs(\n geography = \"tract\",\n variables = \"B19013_001\",\n state = \"IL\",\n geometry = TRUE\n) |&gt;\n mapview::mapview(\n zcol = \"estimate\",\n layer.name = \"Median household income\"\n)\n\nGetting data from the 2017-2021 5-year ACS\n\n\nWarning: • You have not set a Census API key. Users without a key are limited to 500\nqueries per day and may experience performance limitations.\nℹ For best results, get a Census API key at\nhttp://api.census.gov/data/key_signup.html and then supply the key to the\n`census_api_key()` function to use it throughout your tidycensus session.\nThis warning is displayed once per session.\n\n\nDownloading feature geometry from the Census website.  To cache shapefiles for use in future sessions, set `options(tigris_use_cache = TRUE)`.\n\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |=                                                                     |   1%\n  |                                                                            \n  |=                                                                     |   2%\n  |                                                                            \n  |==                                                                    |   2%\n  |                                                                            \n  |==                                                                    |   3%\n  |                                                                            \n  |===                                                                   |   4%\n  |                                                                            \n  |====                                                                  |   5%\n  |                                                                            \n  |====                                                                  |   6%\n  |                                                                            \n  |=====                                                                 |   7%\n  |                                                                            \n  |======                                                                |   9%\n  |                                                                            \n  |=======                                                               |  10%\n  |                                                                            \n  |========                                                              |  12%\n  |                                                                            \n  |=========                                                             |  13%\n  |                                                                            \n  |==========                                                            |  14%\n  |                                                                            \n  |============                                                          |  17%\n  |                                                                            \n  |============                                                          |  18%\n  |                                                                            \n  |=============                                                         |  18%\n  |                                                                            \n  |==============                                                        |  19%\n  |                                                                            \n  |==============                                                        |  20%\n  |                                                                            \n  |=================                                                     |  24%\n  |                                                                            \n  |=================                                                     |  25%\n  |                                                                            \n  |==================                                                    |  26%\n  |                                                                            \n  |====================                                                  |  29%\n  |                                                                            \n  |======================                                                |  32%\n  |                                                                            \n  |=======================                                               |  33%\n  |                                                                            \n  |=========================                                             |  36%\n  |                                                                            \n  |==========================                                            |  38%\n  |                                                                            \n  |===========================                                           |  38%\n  |                                                                            \n  |===========================                                           |  39%\n  |                                                                            \n  |=============================                                         |  41%\n  |                                                                            \n  |===============================                                       |  44%\n  |                                                                            \n  |===============================                                       |  45%\n  |                                                                            \n  |=================================                                     |  47%\n  |                                                                            \n  |===================================                                   |  50%\n  |                                                                            \n  |====================================                                  |  51%\n  |                                                                            \n  |=====================================                                 |  52%\n  |                                                                            \n  |=======================================                               |  55%\n  |                                                                            \n  |=========================================                             |  59%\n  |                                                                            \n  |===========================================                           |  61%\n  |                                                                            \n  |===========================================                           |  62%\n  |                                                                            \n  |=============================================                         |  64%\n  |                                                                            \n  |===============================================                       |  67%\n  |                                                                            \n  |================================================                      |  69%\n  |                                                                            \n  |=================================================                     |  70%\n  |                                                                            \n  |==================================================                    |  72%\n  |                                                                            \n  |===================================================                   |  73%\n  |                                                                            \n  |===================================================                   |  74%\n  |                                                                            \n  |====================================================                  |  75%\n  |                                                                            \n  |=====================================================                 |  76%\n  |                                                                            \n  |======================================================                |  77%\n  |                                                                            \n  |=======================================================               |  78%\n  |                                                                            \n  |========================================================              |  80%\n  |                                                                            \n  |=========================================================             |  81%\n  |                                                                            \n  |===========================================================           |  84%\n  |                                                                            \n  |=============================================================         |  87%\n  |                                                                            \n  |=============================================================         |  88%\n  |                                                                            \n  |==============================================================        |  89%\n  |                                                                            \n  |===============================================================       |  90%\n  |                                                                            \n  |================================================================      |  91%\n  |                                                                            \n  |=================================================================     |  93%\n  |                                                                            \n  |==================================================================    |  94%\n  |                                                                            \n  |====================================================================  |  97%\n  |                                                                            \n  |====================================================================  |  98%\n  |                                                                            \n  |======================================================================| 100%"
  },
  {
    "objectID": "dashboards/shiny_live_r/index.html",
    "href": "dashboards/shiny_live_r/index.html",
    "title": "R-shinylive-demo",
    "section": "",
    "text": "#| standalone: true\n#| viewerHeight: 600\nlibrary(shiny)\nlibrary(bslib)\n\n# Define UI for app that draws a histogram ----\nui &lt;- page_sidebar(\n  sidebar = sidebar(open = \"open\",\n    numericInput(\"n\", \"Sample count\", 100),\n    checkboxInput(\"pause\", \"Pause\", FALSE),\n  ),\n  plotOutput(\"plot\", width=1100)\n)\n\nserver &lt;- function(input, output, session) {\n  data &lt;- reactive({\n    input$resample\n    if (!isTRUE(input$pause)) {\n      invalidateLater(1000)\n    }\n    rnorm(input$n)\n  })\n  \n  output$plot &lt;- renderPlot({\n    hist(data(),\n      breaks = 40,\n      xlim = c(-2, 2),\n      ylim = c(0, 1),\n      lty = \"blank\",\n      xlab = \"value\",\n      freq = FALSE,\n      main = \"\"\n    )\n    \n    x &lt;- seq(from = -2, to = 2, length.out = 500)\n    y &lt;- dnorm(x)\n    lines(x, y, lwd=1.5)\n    \n    lwd &lt;- 5\n    abline(v=0, col=\"red\", lwd=lwd, lty=2)\n    abline(v=mean(data()), col=\"blue\", lwd=lwd, lty=1)\n\n    legend(legend = c(\"Normal\", \"Mean\", \"Sample mean\"),\n      col = c(\"black\", \"red\", \"blue\"),\n      lty = c(1, 2, 1),\n      lwd = c(1, lwd, lwd),\n      x = 1,\n      y = 0.9\n    )\n  }, res=140)\n}\n\n# Create Shiny app ----\nshinyApp(ui = ui, server = server)"
  },
  {
    "objectID": "dashboards/shiny_live_python/index.html",
    "href": "dashboards/shiny_live_python/index.html",
    "title": "Shinylive in Quarto example",
    "section": "",
    "text": "This is a Shinylive application embedded in a Quarto doc.\n#| standalone: true\n\nfrom shiny import *\n\napp_ui = ui.page_fluid(\n    ui.input_slider(\"n\", \"N\", 0, 100, 40),\n    ui.output_text_verbatim(\"txt\"),\n)\n\ndef server(input, output, session):\n    @output\n    @render.text\n    def txt():\n        return f\"The value of n*2 is {input.n() * 2}\"\n\napp = App(app_ui, server)"
  },
  {
    "objectID": "data_visualization/progress_in_public_health/index.html",
    "href": "data_visualization/progress_in_public_health/index.html",
    "title": "Progress in Public Health",
    "section": "",
    "text": "Codedf &lt;- read_csv(\"https://data.cdc.gov/resource/6rkc-nb2q.csv\")\n\n\n\nCodeggplot(df, aes(year, age_adjusted_death_rate, color = leading_causes)) +\n  geom_point() +\n  geom_line()"
  }
]